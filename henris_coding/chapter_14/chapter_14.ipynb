{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14:  Going Deeper---The Mechanics of TensorFlow\n",
    "\n",
    "In this chapter, we will now shift our focus squarely on to TensorFlow itself, and explore in detail the impressive mechanics and features that TensorFlow offers:\n",
    "\n",
    "* Key features and advantages of TensorFlow\n",
    "* TensorFlow ranks and tensors\n",
    "* Understanding and working with TensorFlow graphs\n",
    "* Working with TensorFlow variables\n",
    "* TensorFlow operations with different scopes\n",
    "* Common tensor transformations: working with ranks, shapes and types\n",
    "* Transforming tensors as multi-dimensional arrays\n",
    "* Saving and restoring a model in TensorFlow\n",
    "* Visualising neural network graphs with TensorBoard\n",
    "\n",
    "We will stay hands-on in this chapter, of course, and implement graphs throughout the chapter to explore the main TensorFlow features and concepts.  Along the way, we will also revisit a regression model, explore neural network graph visualisation with TensorBoard, and suggest some ways that you could explore visualising more of the graphs that you'll make through this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow ranks and tensors\n",
    "\n",
    "Tensors are a generalizable mathematical notation for multi-dimensional arrays holding data values, where the dimensionality of a tensor is typically referred as its rank.\n",
    "\n",
    "To make the concept of a **tensor** more intuitive, consider the following figure, which represents tensors of rank 0 and 1 in the first row, and tensors of ranks 2 and 3 in the second row:\n",
    "\n",
    "<img src=\"images/14_01.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the rank and shape of a tensor\n",
    "\n",
    "`tf.rank` will get the rank of a tensor.  It will return a tensor as output.\n",
    "\n",
    "If `X` is a tensor, we can get its shape by using `X.get_shape()`, which will return an object of a special class called `TensorShape`.\n",
    "\n",
    "If we want to index of slice different elements of this object, then we can convert it into a Python list, using the `as_list` method of the tensor class.\n",
    "\n",
    "The following code example illustrates how to retrieve the rank and shape of the tensor in a TensorFlow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "()\n",
      "(4,)\n",
      "(2, 2).\n",
      "\n",
      "Ranks:\n",
      "0\n",
      "1\n",
      "2.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "# define the computation graph\n",
    "with g.as_default():\n",
    "    # define the tensors t1, t2, and t3\n",
    "    t1 = tf.constant(np.pi)\n",
    "    t2 = tf.constant([1, 2, 3, 4])\n",
    "    t3 = tf.constant([[1, 2], [3, 4]])\n",
    "    \n",
    "    # get the ranks of the tensors t1, t2, and t3\n",
    "    r1 = tf.rank(t1)\n",
    "    r2 = tf.rank(t2)\n",
    "    r3 = tf.rank(t3)\n",
    "    # See the following `with` context to see the evaluation of the different r values.\n",
    "    \n",
    "    # Get the shapes of the tensors t1, t2, and t3\n",
    "    s1 = t1.get_shape()\n",
    "    s2 = t2.get_shape()\n",
    "    s3 = t3.get_shape()\n",
    "    print(\"Shapes:\\n{}\\n{}\\n{}.\\n\".format(s1, s2, s3))\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"Ranks:\\n{}\\n{}\\n{}.\".format(r1.eval(), r2.eval(), r3.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the rank of the `t1` tensor is 0 since it is just a scalar (corresponding to the () shape).\n",
    "The rank of the `t2` vector is 1, and since it has four elements, its shape is the on-element tuple `(4,)`.\n",
    "Lastly, the rank of the `2x2` matrix is 3, and its corresponding shape is given by the (2, 2) tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow relies on building a computation graph at its core, and it uses this computation graph to derive relationships between tensors from the input all the way to the output.\n",
    "<img src=\"images/14_02.png\" style=\"width:500px\">\n",
    "\n",
    "As we can see in the above image, a computation graph is simply a network of nodes.  Each node resembles an operation, which applies a function to its input tensor or tensors and returns zero or more tensors as the output.\n",
    "\n",
    "The individual steps for building and compiling such a computation graph in TensorFlow are as follows:\n",
    "1. Instantiate a new, empty computation graph.\n",
    "2. Add nodes (tensors and oeprations) to the computation graph.\n",
    "3. Execute the graph:\n",
    "    - Start a new Session.\n",
    "    - Initialize the variables in the graph.\n",
    "    - Run the computation graph in this session.\n",
    "\n",
    "A graph can be created by calling `tf.Graph()`, and then the nodes can be added as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "    \n",
    "    z = 2*(a-b) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we added nodes to the graph `g` using `with g.as_default()`.\n",
    "\n",
    "A TensorFlow session is an environment in which the operations and tensors of a grap can be executed.  A session object created by calling `tf.Session` that can receive an existing graph (here, `g`) as an argument, as in `tf.Session(graph=g)`.\n",
    "\n",
    "After launching a graph in a TensorFlow session, we can execute its nodes; that is, evaluating its tensors or executings its operators.  Evaluating each individual tensor involves calling its `eval` method inside the current session.  When evaluating a specific tensor in the graph, TensorFlow has to execute all the preceding nodes in the graph until it reaches that particular one.  In case there are one or more placeholders, they would need to be fed.\n",
    "\n",
    "Quite similarly, executing operations can be done using a session's `run` method.  There is also a universal way of running both tensors and operators:  `tf.Session().run()`.  Using this method, multiple tensors and operators can be placed in a list or tuple.  As a result, `tf.Session().run()` will return a list or tuple of the same size.\n",
    "\n",
    "Here, we will launch the previous graph in a TensorFlow session and evaluate the tensor `z` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c ==> 1.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"2*(a-b)+c ==> {}.\".format(sess.run(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we define tensors and operations in a computation graph context within TensorFlow.  A TensorFlow session is then used to execute the operations in the graph and fetch and evaluate the results.\n",
    "\n",
    "Moving on, we will take a deeper look into the different types of nodes that can appear in a computation graph, including placeholders and variables.  Along the way, we will see some other operators that do not return a tensor as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders in TensorFlow\n",
    "\n",
    "Placeholders are predefined tensors with specific types and shapes.\n",
    "\n",
    "These tensors are added to the computation graph using the `tf.placeholder` function, and they do not contain any data.  However, upon the execution of certain nodes in the graph, these placeholders need to be fed with data arrays.\n",
    "\n",
    "In the following sections, we will see how to define placeholders in a graph and how to feed them with data values upon execution.\n",
    "\n",
    "## Defining Placeholders\n",
    "\n",
    "When we defie placeholders, we need to decide what their shape and type should be, according to the shape and type of the data that will be fed through them upon execution.\n",
    "\n",
    "Time for an example:  \n",
    "Here we will define the same graph that was shown in the previous section for evaluating $z = 2\\times (a-b) + c$.  This time, however, we use placeholders for the scalars $a$, $b$, and $c$.  Also, we store the intermediate tensors associated with $r_1$ and $r_2$, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_a = tf.placeholder(tf.int32, shape=[], name='tf_a')\n",
    "    tf_b = tf.placeholder(tf.int32, shape=[], name='tf_b')\n",
    "    tf_c = tf.placeholder(tf.int32, shape=[], name='tf_c')\n",
    "    \n",
    "    r1 = tf_a - tf_b\n",
    "    r2 = 2*r1\n",
    "    z = r2 + tf_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we set the shapes via `shape=[]` since they are scalars (tensors of rand 0).  In the current book, we always precede the placeholder ojects with `tf_` for clarity and to be able to distinguish them from other tensors.\n",
    "\n",
    "It is also very straightforward to define placeholders of higher dimensions: for example, a rank 3 placeholder of type `float` and shape `3x4x5` can be defined as `tf.placeholder(dtype=tf.float32, shape=[3, 4, 5])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding placeholders with data\n",
    "\n",
    "When we execute a node in the graph, we need to create a Python dictionary to feed the values of placeholders with data arrays.  This dictionary is passed as the input argument `feed_dict` to a session's `run` method.\n",
    "\n",
    "In the previous graph, we added three placeholders of the type `tf.int32` to feed scalrs for compuring `z`.  Now, in order to evaluate the results tensor `z`, we can feed arbitrary integer values (here `1`, `2`, and `3`) to the placeholders as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: 1.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    feed = {tf_a: 1,\n",
    "           tf_b: 2,\n",
    "           tf_c: 3}\n",
    "    print('z: {}.'.format(sess.run(z, feed_dict=feed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining placeholders for data arrays with varying batchsizes.\n",
    "\n",
    "Sometimes, when we are developing a neural network model, we may deal with mini-batches of data that have different sizes.\n",
    "\n",
    "A useful feature of placeholders is that we can specify `None` for the dimension that is varying in size.  For example, we can create a placeholder of rank 2, where the first dimension is unknown (or may vary), as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32, shape=[None, 2], name='tf_x')\n",
    "    x_mean = tf.reduce_mean(tf_x, axis=0, name='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can evaluate `x_mean` with two different inputs, namely `x1` and `x2`, which are NumPy arrays of shape `(5, 2)` and `(10, 2)`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding data with shape: (5, 2).\n",
      "Result: [0.62 0.47].\n",
      "\n",
      "Feeding data with shape: (10, 2).\n",
      "Result: [0.46 0.49].\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    x1 = np.random.uniform(low=0, high=1, size=(5,2))\n",
    "    print('Feeding data with shape: {}.'.format(x1.shape))\n",
    "    print('Result: {}.'.format(sess.run(x_mean, feed_dict={tf_x: x1})))\n",
    "    \n",
    "    x2 = np.random.uniform(low=0, high=1, size=(10,2))\n",
    "    print('\\nFeeding data with shape: {}.'.format(x2.shape))\n",
    "    print('Result: {}.'.format(sess.run(x_mean, feed_dict={tf_x: x2})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables in TensorFlow\n",
    "\n",
    "In the context of TensorFlow, variables are a special type of tensor object that allows us to store and update the parameters of our models in a TensorFlow session during training.  The following sections explain how we can:\n",
    "1. define variables in a graph,\n",
    "2. initialize those variables in a session,\n",
    "3. organise variables via the so-called variable scope,\n",
    "4. and re-use existing variables.\n",
    "\n",
    "TensorFlow variables store the parameters of a model that can be updated during training, for example, the weights in the input, hidden, and output layers of a neural network.  When we define a variable, we need to initalize it with a tensor of values.\n",
    "\n",
    "TensorFlow provides two ways for defining variables:\n",
    "1. `tf.Variable(<initial-value>, name=\"variable-name\")`\n",
    "2. `tf.get_variable(name, ...)`\n",
    "\n",
    "The first one, `tf.Variable`, is a class that creates an object for a new variable and adds it to the graph.  Note that `tf.Variable` does not have an explicit way to determine `shape` and `dtype`; the shape and type are set to be the same as those of the initial values.\n",
    "\n",
    "The second option, `tf.get_variable`, can be used to reuse an existing variable with a given name (if the name exists in the graph), or to create a new one if the name does not exist.  Furthermore, `tf.get_variable` provides an explicit way to set `shape` and `dtype`; these parameters are only required when creating a new variable, not reusing existing ones.\n",
    "\n",
    "The advantage of `tf.get_variable` over `tf.Variable` is two-fold:\n",
    "1. `tf.get_variable` allows us to reuse existing variables.\n",
    "2. secondly, it already uses the popular Xavier/Glorot initialization scheme by default.\n",
    "\n",
    "Besides the initializer, the `get_variable` function provides other parameters to control the tensor, such as adding a regularizer for the variable.  If you are interested in learning more about these parameters, feel free to read the documentation of `tf.get_variable` at <https://www.tensorflow.org/api_docs/python/tf/get_variable>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier (or Glorot) initialisation\n",
    "\n",
    "The general idea behind Xavier initialization is to roughly balance the variance of the gradients across the different layers.  Otherwise, one layer may get too much attention during training while the other layer lags behind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either initialization technique, it is important to note that the initial vales are not set until we launch the graph in `tf.Session` and explicity run the initializer operator in that session.\n",
    "\n",
    "Here is an example of creating a variable object where the initial values are created from a NumPy array.  The `dtype` data type of this tensor is `tf.int64`, which is automatically inferred from its NumPy array input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int64_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w')\n",
    "    \n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising Variables\n",
    "\n",
    "Tensors that are defined as variables are not allocated in memory and contain no values until they are initialised.  Therefore, before executing any node in the computation graph, we must initialise the variables that are within the path to the node that we want to execute.\n",
    "\n",
    "TensorFlow provides a function named `tf.global_variables_initializer` that returns an operator for initializing all the variables that exist in a computation graph.  Then executing this operator will initialize the variables as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Scope.\n",
    "\n",
    "When we create a variable scope, the name of operations and tensors that are created within that scope are prefixed with that scope, and those scopes can further be nested.\n",
    "\n",
    "For example, if we have two subnetworks, where each subnetwork has several layers, we can define two scopes named `net_A` and `net_B`, respectively.  Then, each layer layer will we defined within one of these scopes.\n",
    "\n",
    "Let us see how the variable names will turn out in the following code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'net_A/layer-1/weights:0' shape=(10, 4) dtype=float32_ref>\n",
      "<tf.Variable 'net_A/layer-2/weights:0' shape=(20, 10) dtype=float32_ref>\n",
      "<tf.Variable 'net_B/layer-1/weights:0' shape=(10, 4) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    with tf.variable_scope('net_A'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w1 = tf.Variable(tf.random_normal(shape=(10,4)), name=\"weights\")\n",
    "        with tf.variable_scope('layer-2'):\n",
    "            w2 = tf.Variable(tf.random_normal(shape=(20,10)), name=\"weights\")\n",
    "    with tf.variable_scope('net_B'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w3 = tf.Variable(tf.random_normal(shape=(10,4)), name=\"weights\")\n",
    "    \n",
    "    print(w1)\n",
    "    print(w2)\n",
    "    print(w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the variable names are now prefixed with their nested scopes, separated by the forward slash (/) symbol.\n",
    "\n",
    "For more information about variable scoping, read the documentation at:\n",
    "* <https://www.tensorflow.org/programmers_guide/variable_scope>, and\n",
    "* <https://www.tensorflow.org/api_docs/python/tf/variable_scope>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing variables:\n",
    "\n",
    "Let's imagine that we're developing a somewhat complex neural network model that has a classifier whose input data comes from more that one source.  For example, we'll assume that we have data $(X_A, y_A)$ coming from source $A$, and data $(X_B, y_B)$ that comes from source $B$.  In this example, we will design our graph in such a way that it will use the data from only one source as the input tensor to build the network.  Then, we can feed the data from the other source to the same classifier.\n",
    "\n",
    "In the following example, we assume that data from source $A$ is fed through a placeholder, and source $B$ is the output of a generator network.  We will build the generator network by calling the `build_generator` function within the `generator` scope, then we will add a classifier by calling `build_classifier` within the `classifier` scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "### Helper functions ###\n",
    "\n",
    "def build_classifier(data, labels, n_classes=2):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    weights = tf.get_variable(name=\"weights\", shape=(data_shape[1], n_classes), dtype=tf.float32)\n",
    "    bias = tf.get_variable(name=\"bias\", initializer=tf.zeros(shape=n_classes))\n",
    "    logits = tf.add(tf.matmul(data, weights), bias, name=\"logits\")\n",
    "    return logits, tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "def build_generator(data, n_hidden):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    w1 = tf.Variable(tf.random_normal(shape=(data_shape[1], n_hidden)), name=\"w1\")\n",
    "    b1 = tf.Variable(tf.zeros(shape=n_hidden), name=\"b1\")\n",
    "    hidden = tf.add(tf.matmul(data, w1), b1, name=\"hidden_pre-activation\")\n",
    "    hidden = tf.nn.relu(hidden, name=\"hidden_activation\")\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_normal(shape=(n_hidden, data_shape[1])), name=\"w2\")\n",
    "    b2 = tf.Variable(tf.zeros(shape=data_shape[1]), name=\"b2\")\n",
    "    output = tf.add(tf.matmul(hidden, w2), b2, name=\"output\")\n",
    "    return output, tf.nn.sigmoid(output)\n",
    "\n",
    "### Build the Graph ###\n",
    "\n",
    "batch_size=64\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100), dtype=tf.float32, name=\"tf_X\")\n",
    "    \n",
    "    # build the generator\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "    \n",
    "    # build the classifier\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        # classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X, labels=tf.ones(shape=batch_size))\n",
    "        \n",
    "        # reuse the classifier for generated data\n",
    "        scope.reuse_variables()\n",
    "        cls2_out2 = build_classifier(data=gen_out1[1], labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have called the `build_classifier` function 2 times:\n",
    "* The first call causes the building of the network.\n",
    "* Then, we call `scope.reuse_variables()` and call that function again.  \n",
    "As a result, the second call does not create new variables; instead, it reuses the same variables.\n",
    "\n",
    "Alternatively, we could reuse the variables by specifying the `reuse=True` parameter, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100), dtype=tf.float32, name=\"tf_X\")\n",
    "    \n",
    "    # build the generator\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "    \n",
    "    # build the classifier\n",
    "    with tf.variable_scope(\"classifier\"):\n",
    "        # classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X, labels=tf.ones(shape=batch_size))\n",
    "    \n",
    "    with tf.variable_scope(\"classifier\", reuse=True):\n",
    "        # reuse the classifier for generated data\n",
    "        cls_out2 = build_classifier(data=gen_out1[1], labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a regression model\n",
    "\n",
    "Since we have explored placeholders and variables, let us build an example model for regression analysis, where our goal is to implement a linear regression model:\n",
    "\n",
    "$$\n",
    "\\hat{y} = wx + b\n",
    "$$\n",
    "\n",
    "In this model, $w$ and $b$ are the 2 parameters of this simple regression model that need to be defined as variables.  Note that $x$ is the input to the model, which we can define as a placeholder.  Furthermore, for training a regression model, we need to formulate a cost function.  Here, we use the **Mean Squared Error (MSE)** cost function:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n}\\sum_{i=1}^n\\left( y^{(i)} - \\hat{y}^{(i)} \\right)^{2}\n",
    "$$\n",
    "\n",
    "here $y$ is the true value, which is given as the input to this model for training.  Therefore, we need to define $y$ as a placeholder as well.  Finally, $\\hat{y}$, is the prediction output, which will be computed using TensorFlow operations---`tf.matmul` and `tf.add`.\n",
    "\n",
    "The advantage of `tf.add` is that we can provide an additional name for the resulting tensor via the `name` parameter.\n",
    "\n",
    "Therefore, let us summarise all our tensors with their mathematical notations and coding naming, as follows:\n",
    "* Input $x$: `tf_x` defined as a placeholder.\n",
    "* Input $y$: `tf_y` defined as a placeholder.\n",
    "* Model parameter $w$: `weight` defined as a variable.\n",
    "* Model parameter $b$: `bias` defined as a variable.\n",
    "* Model output $\\hat{y}$: `y_hat` returned by TensorFow operations to compute the prediction using the regression model.\n",
    "\n",
    "The code to implement this simple regression model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(123)\n",
    "    \n",
    "    # placeholders\n",
    "    tf_x = tf.placeholder(shape=(None), dtype=tf.float32, name='tf_x')\n",
    "    tf_y = tf.placeholder(shape=(None), dtype=tf.float32, name='tf_y')\n",
    "    \n",
    "    # define the variable (model parameters)\n",
    "    weight = tf.Variable(tf.random_normal(shape=(1, 1), stddev=0.25), name='weight')\n",
    "    bias = tf.Variable(0.0, name=\"bias\")\n",
    "    \n",
    "    # build the model\n",
    "    y_hat = tf.add(weight * tf_x, bias, name='y_hat')\n",
    "    \n",
    "    # compute the cost\n",
    "    cost = tf.reduce_mean(tf.square(tf_y - y_hat), name=\"cost\")\n",
    "    \n",
    "    # train the model\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optim.minimize(cost, name='train_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built the graph, our next steps are to create a session to launch the graph and train the model.  But before we go any further, let's see how we can evaluate tensors and execute operations.  We will create a random regression data with one feature, using the `make_random_data` function and visualising the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a random toy dataset for regression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=4, size=200)\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        r = np.random.normal(loc=0.0, scale=1, size=None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x - 0.84 + np.array(y)\n",
    "\n",
    "x, y = make_random_data()\n",
    "\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure shows the random regression data that was generated.\n",
    "\n",
    "Now we are ready; let us train the previous model:\n",
    "1. Let's start by creating a TensorFlow session called `sess`.\n",
    "2. Then, we want to initialise our variables, which we can do with `sess.run(tf.global_variables_initializer())`\n",
    "3. Create a `for` loop to\n",
    "    - execute the train operator, and\n",
    "    - calculate the training cost at the same time.\n",
    "\n",
    "Let us combine the two tasks, the first to execute an operator, and the second to evaluate a tensor, into one `sess.run` method call.  The code for this is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: 11.9662.\n",
      "Bias: 0.0014, Weight: -0.2338.\n",
      "______________________________\n",
      "Epoch   50: 6.4436.\n",
      "Bias: 0.0471, Weight: 0.2834.\n",
      "______________________________\n",
      "Epoch  100: 3.8575.\n",
      "Bias: 0.0540, Weight: 0.6387.\n",
      "______________________________\n",
      "Epoch  150: 2.6160.\n",
      "Bias: 0.0365, Weight: 0.8845.\n",
      "______________________________\n",
      "Epoch  200: 1.9946.\n",
      "Bias: 0.0043, Weight: 1.0560.\n",
      "______________________________\n",
      "Epoch  250: 1.6630.\n",
      "Bias: -0.0364, Weight: 1.1770.\n",
      "______________________________\n",
      "Epoch  300: 1.4699.\n",
      "Bias: -0.0814, Weight: 1.2635.\n",
      "______________________________\n",
      "Epoch  350: 1.3458.\n",
      "Bias: -0.1280, Weight: 1.3265.\n",
      "______________________________\n",
      "Epoch  400: 1.2581.\n",
      "Bias: -0.1745, Weight: 1.3732.\n",
      "______________________________\n",
      "Epoch  450: 1.1914.\n",
      "Bias: -0.2199, Weight: 1.4087.\n",
      "______________________________\n",
      "Epoch  500: 1.1381.\n",
      "Bias: -0.2634, Weight: 1.4363.\n",
      "______________________________\n",
      "Epoch  550: 1.0940.\n",
      "Bias: -0.3047, Weight: 1.4584.\n",
      "______________________________\n",
      "Epoch  600: 1.0570.\n",
      "Bias: -0.3437, Weight: 1.4764.\n",
      "______________________________\n",
      "Epoch  650: 1.0256.\n",
      "Bias: -0.3803, Weight: 1.4915.\n",
      "______________________________\n",
      "Epoch  700: 0.9987.\n",
      "Bias: -0.4145, Weight: 1.5044.\n",
      "______________________________\n",
      "Epoch  750: 0.9758.\n",
      "Bias: -0.4464, Weight: 1.5156.\n",
      "______________________________\n",
      "Epoch  800: 0.9561.\n",
      "Bias: -0.4761, Weight: 1.5255.\n",
      "______________________________\n",
      "Epoch  850: 0.9392.\n",
      "Bias: -0.5038, Weight: 1.5344.\n",
      "______________________________\n",
      "Epoch  900: 0.9247.\n",
      "Bias: -0.5294, Weight: 1.5424.\n",
      "______________________________\n",
      "Epoch  950: 0.9123.\n",
      "Bias: -0.5533, Weight: 1.5496.\n",
      "______________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train/test splits\n",
    "x_train, y_train = x[:100], y[:100]\n",
    "x_test, y_test = x[100:], y[100:]\n",
    "\n",
    "n_epochs = 1000\n",
    "training_costs = []\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _ = sess.run([cost, train_op], feed_dict={tf_x: x_train, tf_y: y_train})\n",
    "        \n",
    "        training_costs.append(c)\n",
    "        if not e % 50:\n",
    "            print(\"Epoch {:4d}: {:.4f}.\".format(e, c))\n",
    "            print(\"Bias: {:.4f}, Weight: {:.4f}.\".format(sess.run(bias), sess.run(weight)[0][0]))\n",
    "            print(\"{:_^30}\".format(\"\"))\n",
    "\n",
    "plt.plot(training_costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code generates the above graph that shows the training costs after each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing objects in a TensorFlow graph using their names.\n",
    "\n",
    "Executing variables and operators by their names is very useful in many scenarios.  For example, we may develop a model in a separate module; and thus the variables are not avalable in a different Python scope according to Python scoping rules.  However, if we have a graph, we can execute the nodes of the graph using their **names in the graph.**\n",
    "\n",
    "This can be done easily by changing the `sess.run` method from the previous code example, using the variable name of the **cost** in the graph rather than the Python variable `cost` by changing:  \n",
    "`sess.run([cost, train_op], ...)` to `sess.run(['cost:0', 'train_op'], ...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0, 11.9662.\n",
      "Epoch   50, 6.4436.\n",
      "Epoch  100, 3.8575.\n",
      "Epoch  150, 2.6160.\n",
      "Epoch  200, 1.9946.\n",
      "Epoch  250, 1.6630.\n",
      "Epoch  300, 1.4699.\n",
      "Epoch  350, 1.3458.\n",
      "Epoch  400, 1.2581.\n",
      "Epoch  450, 1.1914.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # first, run the variables initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _ = sess.run(['cost:0', 'train_op'], feed_dict={'tf_x:0': x_train, 'tf_y:0': y_train})\n",
    "        training_costs.append(c)\n",
    "        if e%50 == 0:\n",
    "            print('Epoch {:4d}, {:.4f}.'.format(e, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are evaluating the cost by its name, which is `'cost:0'`, and executing the train operator by its name: `'train_op'`.  Also, in `feed_dict`, instead of using `tf_x: x_train`, we are using `'tf_x:0': x_train`.\n",
    "\n",
    "Notice that TensorFlow adds a suffix `':0'` to the name of the tensors.  However, the names of operators do not have any suffix like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a model in TensorFlow.\n",
    "\n",
    "Once the execution of the preceding statements are finished and we exit the `tf.Session` environment, all the variables and their allocated memories are freed.\n",
    "\n",
    "One solution is to train a model, and as soon as the training is finished, we can feed it our test set.  However, this is not a good approach since deep neural network models are typically trained over multiple hours, days, or even weeks.\n",
    "\n",
    "The best approach, is to save the trained model for future use.  For this purpose, we need to add a new node to the graph, and instance of the `tf.train.Saver` class, which we call `saver`.\n",
    "\n",
    "In the following code, we are adding `saver` to the graph `g`, then we retrain the model, and finally make a call to `saver.save()` to save the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 <---> 11.9662.\n",
      "Epoch   50 <---> 6.4436.\n",
      "Epoch  100 <---> 3.8575.\n",
      "Epoch  150 <---> 2.6160.\n",
      "Epoch  200 <---> 1.9946.\n",
      "Epoch  250 <---> 1.6630.\n",
      "Epoch  300 <---> 1.4699.\n",
      "Epoch  350 <---> 1.3458.\n",
      "Epoch  400 <---> 1.2581.\n",
      "Epoch  450 <---> 1.1914.\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    n_epochs = 500\n",
    "    training_costs = []\n",
    "    with tf.Session(graph=g) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # train the model for n epochs\n",
    "        for e in range(n_epochs):\n",
    "            c, _ = sess.run([cost, train_op], feed_dict={tf_x: x_train, tf_y: y_train})\n",
    "            \n",
    "            training_costs.append(c)\n",
    "            if not e % 50:\n",
    "                print(\"Epoch {:4d} <---> {:.4f}.\".format(e, c))\n",
    "        \n",
    "        saver.save(sess, \"./trained-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of this new statement, three files are created with the extensions:\n",
    "* `.data`\n",
    "* `.index`\n",
    "* `.meta`\n",
    "\n",
    "TensorFlow uses Protocol Buffers, which is a language-neutral way for serializing structured data.\n",
    "\n",
    "Restoring a trained model requires two steps:\n",
    "1. Rebuild the graph that has the same nodes and names as the saved model.\n",
    "2. Restore the saved variables in a new `tf.Session` environment.\n",
    "\n",
    "All of the information regarding the graph is saved as metadata in the file with the `.meta` extension.  Using the following code, we rebuild the graph by importing it from the `meta` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph(\"./trained-model.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.train.import_meta_graph` function recreates the graph that is saved in the `./trained-model.meta` file.  After recreating the graph, we can use the `new_saver` object to restore the parameters of the model in that session and execute it.  The complete code to run the model on a test set is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained-model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph(\"./trained-model.meta\")\n",
    "    new_saver.restore(sess, \"./trained-model\")\n",
    "    \n",
    "    y_pred = sess.run(\"y_hat:0\", feed_dict={\"tf_x:0\": x_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we evaluated the $\\hat{y}$ tensor by its name that was given previously: `y_hat:0`.  Also, we needed to feed the values for the `tf_x` placeholder, which is also done by its name: `'tf_x:0'`.  In this case, there is no need to feed the values for the true $y$ values.  This is because executing the `y_hat` node does not depend on `tf_y` in the computation graph that we built.\n",
    "\n",
    "Now, let us visualize the predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained-model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_arr = np.arange(-2, 4, 0.1)\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph(\"./trained-model.meta\")\n",
    "    new_saver.restore(sess, \"./trained-model\")\n",
    "    \n",
    "    y_arr = sess.run(\"y_hat:0\", feed_dict={\"tf_x:0\": x_arr})\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, \"bo\")\n",
    "plt.plot(x_test, y_test, \"bo\", alpha=0.3)\n",
    "plt.plot(x_arr, y_arr.T[:, 0], \"-r\", lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph contains both the training data and test data.\n",
    "\n",
    "Since the training stage of large models can take several hours to days, we can break the training phase into smaller tasks.  For example, if the intended number of epochs is 100, we can break it into 25 tasks, where each task would run 4 epochs one after the other.  For this purpose, we can save the trained model and restore it in the next task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Tensors as multi-dimensional data arrays\n",
    "\n",
    "In this section, we will explore a selection of operators that can be used to transform tensors.  Note that some of these operators work very similar to NumPy array transformations.  However, when we are dealing with tensors with ranks higher than 2, we need to be careful in using such transformation, for example, the transpose of a tensor.\n",
    "\n",
    "We use `tf.get_shape` to get the shape of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T1:0\", shape=(3, 4), dtype=float64)\n",
      "The shape of T1 is (3, 4).\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    arr = np.array([[1., 2., 3., 3.5],\n",
    "                    [4., 5., 6., 6.5],\n",
    "                    [7., 8., 9., 9.5]])\n",
    "    T1 = tf.constant(arr, name=\"T1\")\n",
    "    print(T1)\n",
    "    s = T1.get_shape()\n",
    "    print(\"The shape of T1 is {}.\".format(s))\n",
    "    T2 = tf.Variable(tf.random_normal(shape=s))\n",
    "    print(T2)\n",
    "    T3 = tf.Variable(tf.random_normal(shape=(s.as_list()[0],)))\n",
    "    print(T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot slice or index `s` for creating `T3`, therefore, we converted `s` into a regular Python list by `s.as_list()` and then used the usual indexing conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see how we can reshape tensors.  In TensorFlow, we use the function `tf.reshape` to reshape a tensor.  As is the case for Numpy, one dimension can be set to `-1` so that the size of the new dimension will be inferred based on the total size of the array and the other remaining dimension that are specified.\n",
    "\n",
    "In the following code, we reshape the tensor `T1` to `T4` and `T5`, both of which have rank 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T4:0\", shape=(1, 1, 12), dtype=float64)\n",
      "Tensor(\"T5:0\", shape=(1, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    T4 = tf.reshape(T1, shape=[1, 1, -1], name=\"T4\")\n",
    "    print(T4)\n",
    "    T5 = tf.reshape(T1, shape=[1, 3, -1], name=\"T5\")\n",
    "    print(T5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us print the elements of `T4` and `T5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  2.  3.  3.5 4.  5.  6.  6.5 7.  8.  9.  9.5]]]\n",
      "\n",
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(T4))\n",
    "    print()\n",
    "    print(sess.run(T5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.transpose` function is used to transpose tensors in TensorFlow, and in addition to a regular transpose operation, we can change the order of the dimensions in any way we want by specifying the order in `perm=[...]`.  Here follows an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with g.as_default():\n",
    "    T6 = tf.transpose(T5, perm=[2,1,0], name=\"T6\")\n",
    "    print(T6)\n",
    "    \n",
    "    T7 = tf.transpose(T5, perm=[0,2,1], name=\"T7\")\n",
    "    print(T7)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"T6 = {}.\".format(sess.run(T6)))\n",
    "    print(\"T7 = {}.\".format(sess.run(T7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can also split a tensor into a list of subtensors using the `tf.split` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'T8:0' shape=(1, 3, 2) dtype=float64>, <tf.Tensor 'T8:1' shape=(1, 3, 2) dtype=float64>]\n",
      "T8:0 =\n",
      "[[[1. 2.]\n",
      "  [4. 5.]\n",
      "  [7. 8.]]].\n",
      "____________________\n",
      "T8:1 =\n",
      "[[[3.  3.5]\n",
      "  [6.  6.5]\n",
      "  [9.  9.5]]].\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    t5_split = tf.split(T5, num_or_size_splits=2, axis=2, name=\"T8\")\n",
    "    print(t5_split)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"T8:0 =\\n{}.\".format(sess.run(\"T8:0\")))\n",
    "    print(\"{:_^20}\".format(\"\"))\n",
    "    print(\"T8:1 =\\n{}.\".format(sess.run(\"T8:1\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that the output is not a tensor object anymore; rather, it is a list of tensors.  The name of these subtensors are `'T8:0'` and `'T8:1'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful transformation is the concatenation of multiple tensors.  If we have a list of tensors with the same shape and `dtype`, we can combine them into one big tensor using the `tf.concat` function.  An example is given in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"t1:0\", shape=(5, 1), dtype=float32)\n",
      "Tensor(\"t2:0\", shape=(5, 1), dtype=float32)\n",
      "Tensor(\"t3:0\", shape=(10, 1), dtype=float32)\n",
      "Tensor(\"t4:0\", shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    t1 = tf.ones(shape=(5,1), dtype=tf.float32, name=\"t1\")\n",
    "    t2 = tf.zeros(shape=(5,1), dtype=tf.float32, name=\"t2\")\n",
    "    print(t1)\n",
    "    print(t2)\n",
    "    \n",
    "    t3 = tf.concat([t1, t2], axis=0, name=\"t3\")\n",
    "    t4 = tf.concat([t1, t2], axis=1, name=\"t4\")\n",
    "    print(t3)\n",
    "    print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print the values of these concatenated tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "______________________________\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(t3.eval())\n",
    "    print(\"{:_^30}\".format(\"\"))\n",
    "    print(t4.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing control flow mechanics in building graphs:\n",
    "\n",
    "TensorFlow provides a mechanism for making decisions when building a graph.  However, there are some subtle differences when we use Python's control flow statements compared to TensorFlow's control flow functions, when constructing computation graphs.\n",
    "\n",
    "To illustrate these differences with wome simple code examples, let us consider implementing the following equation in TensorFlow:\n",
    "\n",
    "$$\n",
    "\\mathrm{res} = \\begin{cases}\n",
    "x + y & \\mathrm{if\\ } x < y \\\\\n",
    "x - y & \\mathrm{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In the following code, we may naively use Python's `if` statement to build a graph that corresponds to the preceding equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: Tensor(\"result_add:0\", dtype=float32).\n",
      "x < y: True --> Result: 3.0.\n",
      "x < y: False --> Result: 3.0.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x, y = 1.0, 2.0\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32, shape=None, name=\"tf_x\")\n",
    "    tf_y = tf.placeholder(dtype=tf.float32, shape=None, name=\"tf_y\")\n",
    "    \n",
    "    if x < y:\n",
    "        res = tf.add(tf_x, tf_y, name=\"result_add\")\n",
    "    else:\n",
    "        res = tf.subtract(tf_x, tf_y, name=\"result_sub\")\n",
    "    \n",
    "    print(\"Object: {}.\".format(res))\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"x < y: {} --> Result: {}.\".format(x<y, res.eval(feed_dict={\"tf_x:0\": x, \"tf_y:0\": y})))\n",
    "    \n",
    "    x, y = 2.0, 1.0\n",
    "    print(\"x < y: {} --> Result: {}.\".format(x<y, res.eval(feed_dict={\"tf_x:0\": x, \"tf_y:0\": y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the result of the naïve coding.  Note that the `res` object is a tensor named `result_add:0`.  It is very important to understand that in the previous mechanism, the computation has only one branch associated with the addition operator, and the subtract operator has not been called.\n",
    "\n",
    "The TensorFlow computation graph is static, which means that once the computation graph is built, it remains unchanged during the execution process.  So, even when we change the values of `x` and `y` and feed the new values to the graph, these new tensors will go through the same path in the graph.  Therefore, in both cases, we see the same output `3.0`, for `{x,y} = {2,1}` and `{x,y} = {1,2}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us use the control flow mechanism in TensorFlow.  In the following code, we implement the previous equation using the `tf.cond` function instead of Python's `if` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: Tensor(\"cond/Merge:0\", dtype=float32).\n",
      "x < y: True, Result --> 3.0.\n",
      "x < y: False, Result --> 1.0.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x, y = 1.0, 2.0\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32, shape=None, name=\"tf_x\")\n",
    "    tf_y = tf.placeholder(dtype=tf.float32, shape=None, name=\"tf_y\")\n",
    "    res = tf.cond(tf_x < tf_y,\n",
    "                 lambda: tf.add(tf_x, tf_y, name=\"result_add\"),\n",
    "                 lambda: tf.subtract(tf_x, tf_y, name=\"result_sub\"))\n",
    "    print(\"Object: {}.\".format(res))\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"x < y: {}, Result --> {}.\".format(x<y, res.eval(feed_dict={\"tf_x:0\": x, \"tf_y:0\": y})))\n",
    "    \n",
    "    x, y = 2.0, 1.0\n",
    "    print(\"x < y: {}, Result --> {}.\".format(x<y, res.eval(feed_dict={\"tf_x:0\": x, \"tf_y:0\": y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the `res` object is named `\"cond/Merge:0\"`.  In this case, the computation graph has 2 branches with a mechanism to decide which branch to follow at execution time.\n",
    "* Therefore, when `{x,y} = {2,1}` it follows the addition branch and the output will be `3.0`,\n",
    "* while for `{x,y} = {1,2}` the subtraction branch is pursued and the result will be `1.0`.\n",
    "\n",
    "The following figure contrasts the differences in the computation graph of the previous implementation using the Python `if` statement versus TensorFlow's `tf.cond` function:\n",
    "\n",
    "<img src=\"images/14_06.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `tf.cond`, TensorFlow offers several other control flow operators, such as `tf.case` and `tf.while_loop`.  For instance, `tf.case` is the TensorFlow contrl flow equivalent to a Python `if...else` statement.  Consider implementing the following conditional execution in a TensorFlow graph:\n",
    "\n",
    "```python\n",
    "f1 = lambda: tf.constant(1)\n",
    "f2 = lambda: tf.constant(0)\n",
    "result = tf.case([(tf.less(x, y), f1)], default=f2)\n",
    "```\n",
    "\n",
    "Similarly, we can add a `while` loop to a TensorFlow graph that increments the `i` variable by 1 until a threshold value (`threshold`) is reached as follows:\n",
    "\n",
    "```python\n",
    "i = tf.constant(0)\n",
    "threshold = 100\n",
    "c = lambda i: tf.less(i, 100)\n",
    "b = lambda i: tf.add(i, 1)\n",
    "r = tf.while_loop(cond=c, body=b, loop_vars=[i])\n",
    "```\n",
    "\n",
    "For more information on the various control flow operators, have a look at:\n",
    "<https://www.tensorflow.org/api_guides/python/control_flow_ops>\n",
    "\n",
    "You may have noticed that these computation graphs are built by TensorBoard, so now is a great time to take a good look at TensorBoard in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the graph with TensorBoard.\n",
    "\n",
    "A great feature of TensorFlow is TensorBoard, which is a module for visualising the graph as well as visualising the learning of a model.  Visualsing the graph allows us to\n",
    "1. see the connection between nodes,\n",
    "2. explore their dependencies, and\n",
    "3. debut the model if necessary.\n",
    "\n",
    "Let us visualise a network that we have already built, one which consists of a generator and a classifier part.  Using the two helper functions, we will build the graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_classifier(data, labels, n_classes=2):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    weights = tf.get_variable(name=\"weights\", shape=(data_shape[1], n_classes), dtype=tf.float32)\n",
    "    bias = tf.get_variable(name=\"bias\", initializer=tf.zeros(shape=n_classes))\n",
    "    logits = tf.add(tf.matmul(data, weights), bias, name=\"logits\")\n",
    "    return logits, tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "def build_generator(data, n_hidden):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    w1 = tf.Variable(tf.random_normal(shape=(data_shape[1], n_hidden)), name=\"w1\")\n",
    "    b1 = tf.Variable(tf.zeros(shape=n_hidden), name=\"b1\")\n",
    "    hidden = tf.add(tf.matmul(data, w1), b1, name=\"hidden_pre-activation\")\n",
    "    hidden = tf.nn.relu(hidden, name=\"hidden_activation\")\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_normal(shape=(n_hidden, data_shape[1])), name=\"w2\")\n",
    "    b2 = tf.Variable(tf.zeros(shape=data_shape[1]), name=\"b2\")\n",
    "    output = tf.add(tf.matmul(hidden, w2), b2, name=\"output\")\n",
    "    return output, tf.nn.sigmoid(output)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100), dtype=tf.float32, name=\"tf_X\")\n",
    "    \n",
    "    # build the generator:\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "    \n",
    "    # build the classifier:\n",
    "    with tf.variable_scope(\"classifier\") as scope:\n",
    "        # classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X, labels=tf.ones(shape=batch_size))\n",
    "        \n",
    "        # reuse the classifier for the generated data:\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data=gen_out1[1], labels=tf.zeros(shape=batch_size))\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    file_writer = tf.summary.FileWriter(logdir=\"./logs/\", graph=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a new directory: `logs/`.  Now we just need to run the following command in a Linux terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.12.2 at http://henri-GT72VR-7RD:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will print a message, which is a URL address.  You should see that the graph corresponds to this model, as shown in the following figure:\n",
    "\n",
    "<img src=\"images/14_07.png\" style=\"width:500px\">\n",
    "\n",
    "The large rectangular boxes indicate the 2 subnetworks that we built: generator and classifier.  Since we used the `tf.variable_scope` function when we built this graph, all the components of each of these subnetworks are grouped into those rectangular boxes.\n",
    "\n",
    "We can expand these boxes to explore their details:  double-click with your mouse on the box you want to enlarge.  Doing this, we can see the details of the generator subnetworks as show in the following figure:\n",
    "\n",
    "<img src=\"images/14_08.png\" style=\"width:500px\">\n",
    "\n",
    "Next, let us also expand the classifier subnetwork, as shown in the following figure:\n",
    "\n",
    "<img src=\"images/14_09.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending your TensorBoard experience\n",
    "\n",
    "For more information and examples for graph visualisation, visit the official TensorFlow tutorials page at <https://www.tensorflow.org/get_started/graph_viz>.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In the next chapter, we'll make use of this library to implement an advanced image classifier: a **Convolutional Neural Network (CNN)**.  CNNs are powerful models and have shown great performance in image classification and computer vision.  We'll cover the basic operations in CNNs, and we'll implement deep convolutional networks for image classification using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
